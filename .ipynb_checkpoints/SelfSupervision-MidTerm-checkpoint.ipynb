{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2960,
     "status": "ok",
     "timestamp": 1605689381252,
     "user": {
      "displayName": "Alexander Dimitrienko",
      "photoUrl": "",
      "userId": "07582037467622387890"
     },
     "user_tz": -180
    },
    "id": "i2WkWgBL4CUB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import losses, layers, models, metrics, Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn import svm, metrics\n",
    "import PIL, PIL.ImageOps, PIL.ImageEnhance, PIL.ImageDraw\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2558,
     "status": "ok",
     "timestamp": 1605689381253,
     "user": {
      "displayName": "Alexander Dimitrienko",
      "photoUrl": "",
      "userId": "07582037467622387890"
     },
     "user_tz": -180
    },
    "id": "ncVLyOSa4CUF"
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5452,
     "status": "ok",
     "timestamp": 1605689384733,
     "user": {
      "displayName": "Alexander Dimitrienko",
      "photoUrl": "",
      "userId": "07582037467622387890"
     },
     "user_tz": -180
    },
    "id": "hUGBTkHz4CUJ"
   },
   "outputs": [],
   "source": [
    "files = []\n",
    "for i in range(6):\n",
    "    name =  ''\n",
    "    if i == 5:\n",
    "        name = 'cifar-10-batches-py/test_batch'\n",
    "    else:\n",
    "        name = 'cifar-10-batches-py/data_batch_' + str(i + 1)\n",
    "    files.append(unpickle(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5116,
     "status": "ok",
     "timestamp": 1605689384734,
     "user": {
      "displayName": "Alexander Dimitrienko",
      "photoUrl": "",
      "userId": "07582037467622387890"
     },
     "user_tz": -180
    },
    "id": "kEB_4w7t4CUM"
   },
   "outputs": [],
   "source": [
    "rotations_num = 4\n",
    "augment_num = 10\n",
    "\n",
    "saved_name = 'selfsupervised'\n",
    "cnn_name = 'mycnn'\n",
    "\n",
    "selfsupervised_epochs = 80\n",
    "selfsupervised_batch_size = 128\n",
    "supervised_epochs = 50\n",
    "supervised_batch_size = 128\n",
    "supervised_trainval_ratio = 1. / 6 #1/6 is implied in CIFAR-10\n",
    "\n",
    "feature_layer_trained = 'conv2_block3_out'\n",
    "feature_layer = 'conv2_block3_out'\n",
    "first_resnet_layer = 'conv2_block1_out'\n",
    "second_resnet_layer = 'conv2_block2_out'\n",
    "feature_layer_cnn = 'out_layer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5203,
     "status": "ok",
     "timestamp": 1605689385208,
     "user": {
      "displayName": "Alexander Dimitrienko",
      "photoUrl": "",
      "userId": "07582037467622387890"
     },
     "user_tz": -180
    },
    "id": "PpYC2nYp4CUP"
   },
   "outputs": [],
   "source": [
    "combined_data = np.zeros((60000 * rotations_num, 32, 32, 3), dtype = np.float32)\n",
    "combined_labels = np.zeros((60000 * rotations_num, rotations_num), dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4779,
     "status": "ok",
     "timestamp": 1605689385208,
     "user": {
      "displayName": "Alexander Dimitrienko",
      "photoUrl": "",
      "userId": "07582037467622387890"
     },
     "user_tz": -180
    },
    "id": "76MQkXH-YTkq"
   },
   "outputs": [],
   "source": [
    "true_labels = np.zeros((60000 * rotations_num, 10), dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 589508,
     "status": "ok",
     "timestamp": 1605689970454,
     "user": {
      "displayName": "Alexander Dimitrienko",
      "photoUrl": "",
      "userId": "07582037467622387890"
     },
     "user_tz": -180
    },
    "id": "qDJWyucW4CUT"
   },
   "outputs": [],
   "source": [
    "for i in range(len(files)):\n",
    "    data_len = files[i][b\"data\"].shape[0]\n",
    "    \n",
    "    for j in range(data_len):\n",
    "        row = files[i][b\"data\"][j]\n",
    "        true_labels[rotations_num * (data_len * i + j)][files[i][b\"labels\"][j]] = 1.\n",
    "        \n",
    "        for k in range(files[i][b\"data\"].shape[1]):\n",
    "            combined_data[rotations_num * (data_len * i + j)][(k & 1023) >> 5][k & 31][k >> 10] = row[k]\n",
    "        combined_labels[rotations_num * (data_len * i + j)][0] = 1.\n",
    "        \n",
    "        for t in range(1, rotations_num):\n",
    "            true_labels[rotations_num * (data_len * i + j) + t][files[i][b\"labels\"][j]] = 1.\n",
    "            combined_data[rotations_num * (data_len * i + j) + t] = np.rot90(combined_data[rotations_num * (data_len * i + j)], t)\n",
    "            combined_labels[rotations_num * (data_len * i + j) + t][t] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "executionInfo": {
     "elapsed": 589036,
     "status": "ok",
     "timestamp": 1605689970458,
     "user": {
      "displayName": "Alexander Dimitrienko",
      "photoUrl": "",
      "userId": "07582037467622387890"
     },
     "user_tz": -180
    },
    "id": "5alMJ4a_4CUV",
    "outputId": "58c46fee-16c9-4b80-98a9-04f0d66459c2",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "r = random.randint(0, 60000)\n",
    "\n",
    "for i in range(rotations_num):\n",
    "    plt.imshow(combined_data[r * rotations_num + i].astype(int))\n",
    "    plt.show()\n",
    "    print(combined_labels[r * rotations_num + i])\n",
    "    print(true_labels[r * rotations_num + i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_data = preprocess_input(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "qHtoMw2t4CUb"
   },
   "outputs": [],
   "source": [
    "def plot_training(**kwargs):\n",
    "    plt.figure(figsize = (10, 10))\n",
    "    \n",
    "    for k, v in kwargs.items():\n",
    "        if k != 'name' and k != 'filename':\n",
    "            plt.plot(v, label=k)\n",
    "            \n",
    "    plt.grid(True)\n",
    "    if 'name' in kwargs:\n",
    "        plt.title(kwargs['name'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend(loc='lower right')\n",
    "    if 'filename' in kwargs:\n",
    "        plt.savefig(kwargs['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kPX0I6P74CUd"
   },
   "outputs": [],
   "source": [
    "def get_feat_model():\n",
    "    inputs = tf.keras.Input((32, 32, 3))\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.4, name='out_layer')(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(200, kernel_regularizer=regularizers.l2(l = 0.0001), kernel_initializer='he_uniform')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(200, kernel_regularizer=regularizers.l2(l = 0.0001), kernel_initializer='he_uniform')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(rotations_num, kernel_regularizer=regularizers.l2(l = 0.0001), activation = 'softmax')(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs = inputs, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model():\n",
    "    base = ResNet50(include_top=False, weights=None, input_shape=(32, 32, 3))\n",
    "    l = base.get_layer(feature_layer_trained).output\n",
    "    l = layers.Flatten()(l)\n",
    "    l = layers.BatchNormalization()(l)\n",
    "    l = layers.Dropout(0.5)(l)\n",
    "    l = layers.Dense(200, kernel_regularizer=regularizers.l1_l2(l1 = 0.0001, l2 = 0.0005), kernel_initializer='he_uniform')(l)\n",
    "    l = layers.BatchNormalization()(l)\n",
    "    l = layers.Activation('relu')(l)\n",
    "    l = layers.Dropout(0.5)(l)\n",
    "    l = layers.Dense(200, kernel_regularizer=regularizers.l1_l2(l1 = 0.0001, l2 = 0.0005), kernel_initializer='he_uniform')(l)\n",
    "    l = layers.BatchNormalization()(l)\n",
    "    l = layers.Activation('relu')(l)\n",
    "    l = layers.Dropout(0.5)(l)\n",
    "    l = layers.Dense(rotations_num, kernel_regularizer=regularizers.l1_l2(l1 = 0.00005, l2 = 0.0001), activation = 'softmax')(l)\n",
    "    \n",
    "    return tf.keras.Model(inputs = base.input, outputs = l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch, lr):\n",
    "    if epoch == 50:\n",
    "        return lr / 5.\n",
    "    if epoch == 40:\n",
    "        return lr / 5.\n",
    "    if epoch == 30:\n",
    "        return lr / 5.\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule_conv(epoch, lr):\n",
    "    print(lr)\n",
    "    if epoch == 80:\n",
    "        return lr / 5.\n",
    "    if epoch == 60:\n",
    "        return lr / 5.\n",
    "    if epoch == 40:\n",
    "        return lr / 5.\n",
    "    if epoch == 20:\n",
    "        return lr / 5.\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule_cls(epoch, lr):\n",
    "    print(lr)\n",
    "    if epoch == 40:\n",
    "        return lr / 5.\n",
    "    if epoch == 30:\n",
    "        return lr / 5.\n",
    "    if epoch == 20:\n",
    "        return lr / 5.\n",
    "    if epoch == 10:\n",
    "        return lr / 5.\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule_linear(epoch, lr):\n",
    "    print(lr)\n",
    "    if epoch < supervised_epochs // 2:\n",
    "        return lr + (0.1 - 0.00001) / supervised_epochs * 2.\n",
    "    else:\n",
    "        return max(lr - (0.1 - 0.00001) / supervised_epochs * 2., 0.00001)\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "rqvEEjX74CUg"
   },
   "outputs": [],
   "source": [
    "def train_feat():\n",
    "    model = get_conv_model()\n",
    "    model.summary()\n",
    "    model.compile(optimizer = optimizers.RMSprop(), loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    log = model.fit(combined_data, combined_labels, \n",
    "                    epochs = selfsupervised_epochs, batch_size = selfsupervised_batch_size, \n",
    "                    shuffle = True, callbacks = [LearningRateScheduler(lr_schedule)])\n",
    "    model.save(saved_name)\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5CGkQvR4CUj",
    "outputId": "120adc8d-7351-475e-aa82-25474b2b1295",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log = train_feat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_4GXBHL4CUn"
   },
   "outputs": [],
   "source": [
    "def get_cls_model(name = saved_name, use_features = True, percent = 100):\n",
    "    if use_features:\n",
    "        model = tf.keras.models.load_model(name)\n",
    "    else:\n",
    "        model = tf.keras.models.load_model('emptyResNet')\n",
    "        \n",
    "    if percent >= 50:\n",
    "        l = model.get_layer(feature_layer).output\n",
    "    else:\n",
    "        l = model.get_layer(first_resnet_layer).output\n",
    "        \n",
    "    #model = tf.keras.models.load_model(cnn_name)\n",
    "    #l = model.get_layer(feature_layer_cnn).output\n",
    "    \n",
    "    l = layers.Flatten()(l)\n",
    "    l = layers.BatchNormalization()(l)\n",
    "    l = layers.Dropout(0.5)(l)\n",
    "    l = layers.Dense(200, kernel_regularizer=regularizers.l1_l2(l1 = 0.0001, l2 = 0.0005), kernel_initializer='he_uniform')(l)\n",
    "    l = layers.BatchNormalization()(l)\n",
    "    l = layers.Activation('relu')(l)\n",
    "    l = layers.Dropout(0.5)(l)\n",
    "    l = layers.Dense(200, kernel_regularizer=regularizers.l1_l2(l1 = 0.0001, l2 = 0.0005), kernel_initializer='he_uniform')(l)\n",
    "    l = layers.BatchNormalization()(l)\n",
    "    l = layers.Activation('relu')(l)\n",
    "    l = layers.Dropout(0.5)(l)\n",
    "    l = layers.Dense(10, kernel_regularizer=regularizers.l1_l2(l1 = 0.0001, l2 = 0.0005), activation = 'softmax')(l)\n",
    "    return tf.keras.Model(inputs = model.input, outputs = l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JwBUGYKx4CUq"
   },
   "outputs": [],
   "source": [
    "def train_cls(train_features = True):\n",
    "    cls_model = get_cls_model()\n",
    "    cls_model.summary()\n",
    "    \n",
    "    if not train_features:\n",
    "        for l in cls_model.layers[:-5]:\n",
    "            l.trainable = False\n",
    "            \n",
    "    cls_model.compile(optimizer = optimizers.RMSprop(), loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    cls_log = cls_model.fit(combined_data[:int(60000 * (1.0 - supervised_trainval_ratio))], \n",
    "                            true_labels[:int(60000 * (1.0 - supervised_trainval_ratio))], \n",
    "                            epochs = supervised_epochs, batch_size = supervised_batch_size, shuffle = True,\n",
    "                            callbacks = [LearningRateScheduler(lr_schedule)],\n",
    "                            validation_data = (combined_data[int(60000 * (1.0 - supervised_trainval_ratio)):60000], \n",
    "                                               true_labels[int(60000 * (1.0 - supervised_trainval_ratio)):60000]))\n",
    "    return cls_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDLC9hEw4CUs",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cls_train_features = train_cls(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwysIrWV4CUv",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cls_no_train_features = train_cls(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UdOvJsoy4CUx"
   },
   "outputs": [],
   "source": [
    "plot_training(name = 'Train accuracy',\n",
    "              fine_tuning_accuracy = cls_train_features.history['accuracy'],\n",
    "              feature_extracting_accuracy = cls_no_train_features.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3YdkFcH4CU0"
   },
   "outputs": [],
   "source": [
    "plot_training(name = 'Validation accuracy',\n",
    "              fine_tuning_accuracy = cls_train_features.history['val_accuracy'],\n",
    "              feature_extracting_accuracy = cls_no_train_features.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Snwmob4x4CU5"
   },
   "outputs": [],
   "source": [
    "labelsPercent = [1, 2, 3, 5, 10, 25, 50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 572768,
     "status": "ok",
     "timestamp": 1605689970459,
     "user": {
      "displayName": "Alexander Dimitrienko",
      "photoUrl": "",
      "userId": "07582037467622387890"
     },
     "user_tz": -180
    },
    "id": "J5JOcjUp4CU7"
   },
   "outputs": [],
   "source": [
    "def shuffle_examples():\n",
    "    #     , ..   n \n",
    "    for i in range(len(examplesForClass)):\n",
    "        random.shuffle(examplesForClass[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 570785,
     "status": "ok",
     "timestamp": 1605689970459,
     "user": {
      "displayName": "Alexander Dimitrienko",
      "photoUrl": "",
      "userId": "07582037467622387890"
     },
     "user_tz": -180
    },
    "id": "sJIwuRIQ4CU9"
   },
   "outputs": [],
   "source": [
    "def generate_labeled_unlabeled(examples, percent, shuffle = True):\n",
    "    #           \n",
    "    if shuffle:\n",
    "        shuffle_examples()\n",
    "    labeled = []\n",
    "    tmp = []\n",
    "    unlabeled = []\n",
    "    \n",
    "    #labeled_nums = [rotations_num * i for i in range(5000 - percent * 50, 5000)]\n",
    "    labeled_nums = [i for i in range((5000 - percent * 50) * rotations_num, 5000 * rotations_num)]\n",
    "    unlabeled_nums = [i for i in range((5000 - percent * 50) * rotations_num)]\n",
    "\n",
    "    for i in range(len(examples)):\n",
    "        for j in labeled_nums:\n",
    "            labeled += [examples[i][j]] #50 == 5000 / 100\n",
    "        for j in unlabeled_nums:\n",
    "            unlabeled += [examples[i][j]]\n",
    "        \n",
    "    return labeled, unlabeled\n",
    "labeled, unlabeled = generate_labeled_unlabeled(examplesForClass, 0, False)\n",
    "len(unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_augmented_labeled_unlabeled(examples, percent, shuffle = True):\n",
    "    #           \n",
    "    if shuffle:\n",
    "        shuffle_examples()\n",
    "    labeled = []\n",
    "    tmp = []\n",
    "    unlabeled = []\n",
    "    \n",
    "    #labeled_nums = [rotations_num * i for i in range(5000 - percent * 50, 5000)]\n",
    "    labeled_nums = [i for i in range((5000 - percent * 50) * augment_num, 5000 * augment_num)]\n",
    "    unlabeled_nums = [i for i in range((5000 - percent * 50) * augment_num)]\n",
    "\n",
    "    for i in range(len(examples)):\n",
    "        for j in labeled_nums:\n",
    "            labeled += [examples[i][j]] #50 == 5000 / 100\n",
    "        for j in unlabeled_nums:\n",
    "            unlabeled += [examples[i][j]]\n",
    "        \n",
    "    return labeled, unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zVKZmOo64CVE"
   },
   "outputs": [],
   "source": [
    "def self_supervised_train(unlabeled, percent, use_datagen = False, **kwargs):\n",
    "    if percent >= 100:\n",
    "        return None\n",
    "    \n",
    "    model = get_conv_model()\n",
    "    model.summary()\n",
    "    model.compile(optimizer = optimizers.Adam(), loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    if use_datagen:\n",
    "        log = model.fit(kwargs['datagen'].flow(np.asarray([combined_data[i] for i in unlabeled]), \n",
    "                    np.asarray([combined_labels[i] for i in unlabeled]),\n",
    "                    batch_size = selfsupervised_batch_size),\n",
    "                    epochs = selfsupervised_epochs, \n",
    "                    steps_per_epoch = len(unlabeled) // selfsupervised_batch_size,\n",
    "                    shuffle = True,\n",
    "                    #callbacks = [LearningRateScheduler(lr_schedule_conv)],\n",
    "                            validation_data = (np.asarray(combined_data[50000 * rotations_num:]), \n",
    "                                               np.asarray(combined_labels[50000 * rotations_num:])))\n",
    "    else:    \n",
    "        log = model.fit(np.asarray([combined_data[i] for i in unlabeled]) / 256., \n",
    "                    np.asarray([combined_labels[i] for i in unlabeled]), \n",
    "                    epochs = selfsupervised_epochs, \n",
    "                    batch_size = selfsupervised_batch_size, \n",
    "                    shuffle = True,\n",
    "                    #callbacks = [LearningRateScheduler(lr_schedule_conv)],\n",
    "                            validation_data = (np.asarray([combined_data[(50000 + i) * rotations_num] for i in range(10000)])  / 256., \n",
    "                                               np.asarray([combined_labels[(50000 + i) * rotations_num] for i in range(10000)])))\n",
    "    model.save(saved_name + \"_\" + str(percent))\n",
    "    \n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKgxJlIT4CVG"
   },
   "outputs": [],
   "source": [
    "def fine_tune(labeled, percent, train_features = True, use_features = True, use_datagen = False, **kwargs):\n",
    "    #cls_model = get_cls_model(saved_name + \"_\" + str(percent))\n",
    "    cls_model = get_cls_model(saved_name, use_features, percent)\n",
    "    \n",
    "    if not train_features:\n",
    "        flag = False\n",
    "        for l in cls_model.layers:\n",
    "            l.trainable = flag\n",
    "            if l.name == feature_layer or l.name == feature_layer_trained:\n",
    "                flag = True\n",
    "                \n",
    "    cls_model.summary()\n",
    "            \n",
    "    cls_model.compile(optimizer = optimizers.Adam(lr=0.001), loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    if use_datagen:\n",
    "        print('Datagen is used...')\n",
    "        cls_log = cls_model.fit(kwargs['datagen'].flow(np.asarray([combined_data[i] for i in labeled]), \n",
    "                            np.asarray([true_labels[i] for i in labeled]),\n",
    "                            batch_size = supervised_batch_size), \n",
    "                            epochs = supervised_epochs,\n",
    "                            steps_per_epoch = len(labeled) // supervised_batch_size, \n",
    "                            shuffle = True,\n",
    "                            validation_data = (np.asarray([combined_data[(50000 + i) * rotations_num] for i in range(10000)]) / 256., \n",
    "                                               np.asarray([true_labels[(50000 + i) * rotations_num] for i in range(10000)])))\n",
    "    else:\n",
    "        cls_log = cls_model.fit(np.asarray([augmented_data[i] for i in labeled]) / 256., \n",
    "                            np.asarray([augmented_labels[i] for i in labeled]), \n",
    "                            epochs = supervised_epochs, batch_size = supervised_batch_size, \n",
    "                            shuffle = True,\n",
    "                            validation_data = (np.asarray([combined_data[(50000 + i) * rotations_num] for i in range(10000)])  / 256., \n",
    "                                               np.asarray([true_labels[(50000 + i) * rotations_num] for i in range(10000)])))\n",
    "    \n",
    "    return cls_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5S_EOaHJ4CVJ"
   },
   "outputs": [],
   "source": [
    "def get_empty_model():\n",
    "    #      \n",
    "    model = get_conv_model()\n",
    "    model.compile(optimizer = optimizers.RMSprop(), loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.save(saved_name + \"_100\")\n",
    "    \n",
    "    return get_cls_model(saved_name + \"_100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_preprocess(data):\n",
    "    output = data / 256.0\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=4,\n",
    "    height_shift_range=4,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=my_preprocess)\n",
    "aug_datagen.fit(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(tf.image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data = np.zeros((50000 * augment_num, 32, 32, 3), dtype = np.float32)\n",
    "augmented_labels = np.zeros((50000 * augment_num, 10), dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50000):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    augmented_data[i * augment_num] = combined_data[i * rotations_num]\n",
    "    augmented_data[i * augment_num + 1] = tf.image.flip_up_down(tf.image.random_contrast(combined_data[i * rotations_num], 0.2, 0.7))\n",
    "    augmented_data[i * augment_num + 2] = tf.image.flip_left_right(tf.image.random_contrast(combined_data[i * rotations_num], 0.2, 0.7))\n",
    "    augmented_data[i * augment_num + 3] = tf.image.random_contrast(combined_data[i * rotations_num], 0.2, 0.7)\n",
    "    augmented_data[i * augment_num + 4] = tf.image.flip_left_right(combined_data[i * rotations_num])\n",
    "    augmented_data[i * augment_num + 5] = tf.image.flip_up_down(combined_data[i * rotations_num])\n",
    "    augmented_data[i * augment_num + 6] = tf.image.random_hue(combined_data[i * rotations_num], 0.3)\n",
    "    augmented_data[i * augment_num + 7] = tf.image.random_saturation(combined_data[i * rotations_num], 5, 10)\n",
    "    augmented_data[i * augment_num + 8] = tf.image.flip_left_right(tf.image.random_hue(combined_data[i * rotations_num], 0.3))\n",
    "    augmented_data[i * augment_num + 9] = tf.image.flip_left_right(tf.image.random_saturation(combined_data[i * rotations_num], 5, 10))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50000):\n",
    "    for j in range(augment_num):\n",
    "            augmented_labels[i * augment_num + j] = true_labels[i * rotations_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r = random.randint(0, 50000)\n",
    "for i in range(augment_num):\n",
    "    plt.imshow(augmented_data[r * augment_num + i].astype(int))\n",
    "    plt.show()\n",
    "    print(augmented_labels[r * augment_num + i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentedExamplesForClass = []\n",
    "for i in range(10):\n",
    "    augmentedExamplesForClass.append([j for j in range(50000 * augment_num) if np.where(augmented_labels[j] == 1)[0][0] == i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLjLXjvQ4CVM"
   },
   "outputs": [],
   "source": [
    "examplesForClass = []\n",
    "for i in range(10):\n",
    "    examplesForClass.append([j for j in range(50000 * rotations_num) if np.where(true_labels[j] == 1)[0][0] == i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(5 * rotations_num):\n",
    "    if(np.where(true_labels[j]==1)[0][0]==6):\n",
    "        print(j)\n",
    "# #     print(np.where(true_labels[j] == 1)[0][0] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labeled, unlabeled = generate_labeled_unlabeled(examplesForClass, 0, False)\n",
    "self_supervised_train(unlabeled, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = []\n",
    "cls_logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 989
    },
    "executionInfo": {
     "elapsed": 29958,
     "status": "error",
     "timestamp": 1605100230880,
     "user": {
      "displayName": "Alexander Dimitrienko",
      "photoUrl": "",
      "userId": "07582037467622387890"
     },
     "user_tz": -180
    },
    "id": "TRtVD-9I4CVP",
    "outputId": "3a012661-c3f8-48ff-a1d3-db504c9aef8b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for p in labelsPercent:\n",
    "    labeled, unlabeled = generate_labeled_unlabeled(examplesForClass, p, False)\n",
    "    #if not os.path.isfile(saved_name + \"_\" + str(p)):\n",
    "    \n",
    "    if not os.path.isfile(saved_name):\n",
    "        logs.append(self_supervised_train(unlabeled, p))\n",
    "    cls_logs.append(fine_tune(labeled, p, True))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Self-supervised with augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for p in labelsPercent:\n",
    "    labeled, unlabeled = generate_augmented_labeled_unlabeled(augmentedExamplesForClass, p, False)\n",
    "    print(len(labeled), len(unlabeled))\n",
    "    cls_logs.append(fine_tune(labeled, p, True, True))        \n",
    "#[0.5505, 0.6021, 0.6382, 0.6691, 0.7135, 0.7671, 0.8060, 0.8448]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(cls_logs)):\n",
    "    print(cls_logs[i].history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_log = self_supervised_train([i for i in range(50000 * rotations_num)], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('selfsupervised_50_backup2')\n",
    "model.summary()\n",
    "l = model.get_layer('conv_feat').output\n",
    "feat = tf.keras.Model(inputs = model.input, outputs = l)\n",
    "y_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = feat.predict(np.asarray([combined_data[(50000 + i) * rotations_num] for i in range(10000)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for p in labelsPercent:\n",
    "    labeled, unlabeled = generate_labeled_unlabeled(examplesForClass, p, False)\n",
    "    features = feat.predict(np.asarray([combined_data[i] for i in labeled]))\n",
    "    clf = svm.SVC(C = 100., kernel = 'rbf')\n",
    "    clf.fit(features, np.asarray([np.argmax(true_labels[i]) for i in labeled]))\n",
    "    y_pred.append(clf.predict(features_test))\n",
    "    print(metrics.accuracy_score(np.asarray([np.argmax(true_labels[(50000 + i) * rotations_num]) for i in range(10000)]), y_pred[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZqgUVhQ_4CVR"
   },
   "outputs": [],
   "source": [
    "plot_dict = {}\n",
    "\n",
    "for i, p in enumerate(labelsPercent):\n",
    "    plot_dict[\"labels_\" + str(p)] = cls_logs[i].history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VOEtN07P4CVT",
    "outputId": "aac9cc73-b8ed-4c62-d0db-688a5a5582fa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_training(name = 'Validation accuracy',\n",
    "              filename = 'self_part_labels',\n",
    "              **plot_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfsupervised_acc = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(labelsPercent):\n",
    "    selfsupervised_acc[p] = cls_logs[i].history['val_accuracy'][-1]\n",
    "print(selfsupervised_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lYBivMPo4CVX"
   },
   "outputs": [],
   "source": [
    "emptyResNet = ResNet50(include_top=False, weights=None, input_shape=(32, 32, 3))\n",
    "emptyResNet.summary()\n",
    "emptyResNet.compile(optimizer = optimizers.Adam(), loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "emptyResNet.save('emptyResNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycnn = get_feat_model()\n",
    "mycnn.summary()\n",
    "mycnn.compile(optimizer = optimizers.Adam(), loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "mycnn.save(cnn_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_supervised = []\n",
    "cls_logs_supervised = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in labelsPercent:\n",
    "    labeled, unlabeled = generate_labeled_unlabeled(examplesForClass, p, False)\n",
    "    cls_logs_supervised.append(fine_tune(labeled, p, True, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supervised with data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=4,\n",
    "    height_shift_range=4, \n",
    "    brightness_range=[0.5, 1.0],\n",
    "    preprocessing_function=my_preprocess)\n",
    "datagen.fit(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for p in labelsPercent:\n",
    "    labeled, unlabeled = generate_augmented_labeled_unlabeled(augmentedExamplesForClass, p, False)\n",
    "    print(len(labeled))\n",
    "    print(len(unlabeled))\n",
    "    cls_logs_supervised.append(fine_tune(labeled, p, True, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_acc = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(labelsPercent):\n",
    "    if i < len(cls_logs_supervised):\n",
    "        supervised_acc[p] = cls_logs_supervised[i].history['val_accuracy'][-1]\n",
    "        \n",
    "print(supervised_acc)\n",
    "#{100: 0.8076, 50: 0.7702, 25: 0.7134, 10: 0.6265, 5: 0.5556, 1: 0.3892, 3: 0.4811, 2: 0.4377}\n",
    "#{1: 0.4231, 2: 0.5026, 3: 0.5475, 5: 0.6002, 10: 0.6714, 25: 0.7411, 50: 0.7959, 100: 0.8420}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "super_v = []\n",
    "self_v = []\n",
    "\n",
    "for p in labelsPercent:\n",
    "    super_v.append(supervised_acc[p])\n",
    "    self_v.append(selfsupervised_acc[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesPerClass = []\n",
    "for p in labelsPercent:\n",
    "    samplesPerClass.append(5000 * p // 100)\n",
    "print(samplesPerClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.plot(samplesPerClass, super_v, 'o-', label='  ')\n",
    "ax.plot(samplesPerClass, self_v, 'o-', label='')\n",
    "ax.grid(True)\n",
    "plt.title(' ', size = 24)\n",
    "plt.xlabel('    ( 5000)', fontsize = 18)\n",
    "plt.ylabel('', fontsize = 18)\n",
    "plt.xscale(\"log\")\n",
    "ax.axis([min(samplesPerClass), max(samplesPerClass), 0., 1.])\n",
    "ax.set_xticks(samplesPerClass)\n",
    "ax.tick_params(labelsize= 18)\n",
    "ax.xaxis.set_major_formatter(ScalarFormatter())\n",
    "ax.legend(loc='lower right', fontsize = 18)\n",
    "plt.savefig('acc_compare_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5MUHwA-4CVZ",
    "outputId": "8d13c1d8-486f-430e-d66f-b24a516f826a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, p in enumerate(labelsPercent):\n",
    "    plot_dict = {}\n",
    "    \n",
    "    plot_dict[\"labels_\" + str(p) + \"_selfsupervised\"] = cls_logs[i].history['val_acc']\n",
    "    plot_dict[\"labels_\" + str(p) + \"_supervised\"] = cls_logs_supervised[i].history['val_acc']\n",
    "    \n",
    "    plot_training(name = 'Validation accuracy for ' + str(p) + \"% of labels\",\n",
    "                  filename = 'self_and_default_' + str(p) + \" labels\",\n",
    "                  **plot_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1562,
     "status": "ok",
     "timestamp": 1605689972038,
     "user": {
      "displayName": "Alexander Dimitrienko",
      "photoUrl": "",
      "userId": "07582037467622387890"
     },
     "user_tz": -180
    },
    "id": "izmuo9qeQiRy"
   },
   "outputs": [],
   "source": [
    "unsupervised_threshold = 0.95\n",
    "unsupervised_loss_coef = 1.0\n",
    "unlabeled_epoch_start = 5\n",
    "\n",
    "semisupervised_epochs = 50\n",
    "semisupervised_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1551,
     "status": "ok",
     "timestamp": 1605689972038,
     "user": {
      "displayName": "Alexander Dimitrienko",
      "photoUrl": "",
      "userId": "07582037467622387890"
     },
     "user_tz": -180
    },
    "id": "EEWfx01uejSP"
   },
   "outputs": [],
   "source": [
    "labelsPercent = [50, 25, 10, 5, 3, 2, 1] #100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1542,
     "status": "ok",
     "timestamp": 1605689972038,
     "user": {
      "displayName": "Alexander Dimitrienko",
      "photoUrl": "",
      "userId": "07582037467622387890"
     },
     "user_tz": -180
    },
    "id": "Lr4woi469A1z"
   },
   "outputs": [],
   "source": [
    "class Augmentator():\n",
    "    def shearX(self, img):\n",
    "        return img.transform(img.size, PIL.Image.AFFINE, (1, (random.choice([-1, 1])) * self.M * 0.3, 0, 0, 1, 0))\n",
    "\n",
    "    def shearY(self, img):\n",
    "        return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, (random.choice([-1, 1])) * self.M * 0.3, 1, 0))\n",
    "\n",
    "    def translateX(self, img):\n",
    "        return img.transform(img.size, PIL.Image.AFFINE, (1, 0, (random.choice([-1, 1])) * self.M * 0.3 * img.size[0], 0, 1, 0))\n",
    "\n",
    "    def translateY(self, img):\n",
    "        return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, (random.choice([-1, 1])) * self.M * 0.3 * img.size[0]))\n",
    "\n",
    "    def rotate(self, img):\n",
    "        return img.rotate((random.choice([-1, 1])) * self.M * 30.0)\n",
    "\n",
    "    def autoContrast(self, img):\n",
    "        return PIL.ImageOps.autocontrast(img)\n",
    "\n",
    "    def invert(self, img):\n",
    "        return PIL.ImageOps.invert(img)\n",
    "\n",
    "    def equalize(self, img):\n",
    "        return PIL.ImageOps.equalize(img)\n",
    "\n",
    "    def solarize(self, img):\n",
    "        return PIL.ImageOps.solarize(img, self.M * 256.0)\n",
    "\n",
    "    def posterize(self, img):\n",
    "        return PIL.ImageOps.posterize(img, int(self.M * 4.0))\n",
    "\n",
    "    def contrast(self, img):\n",
    "        return PIL.ImageEnhance.Contrast(img).enhance(self.M)\n",
    "\n",
    "    def color(self, img):\n",
    "        return PIL.ImageEnhance.Color(img).enhance(self.M)\n",
    "\n",
    "    def brightness(self, img):\n",
    "        return PIL.ImageEnhance.Brightness(img).enhance(self.M)\n",
    "\n",
    "    def sharpness(self, img):\n",
    "        return PIL.ImageEnhance.Sharpness(img).enhance(self.M)\n",
    "    \n",
    "    def __init__(self, N, M):\n",
    "        self.N = N\n",
    "        self.M = M\n",
    "        self.transformations = [self.autoContrast, self.equalize, self.rotate, self.solarize, self.color, self.posterize, self.contrast, self.brightness, self.sharpness, self.shearX, self.shearY, self.translateX, self.translateY]\n",
    "\n",
    "    def __call__(self, img):\n",
    "        chosen_transformations = random.choices(self.transformations, k = self.N)\n",
    "        for f in chosen_transformations:\n",
    "            img = f(img)\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3225,
     "status": "ok",
     "timestamp": 1605689973731,
     "user": {
      "displayName": "Alexander Dimitrienko",
      "photoUrl": "",
      "userId": "07582037467622387890"
     },
     "user_tz": -180
    },
    "id": "k4qWlhmFgJYz"
   },
   "outputs": [],
   "source": [
    "def is_called(func):\n",
    "    def newfunc(*args, **kwargs):\n",
    "        print('Called func!')\n",
    "        func(args, kwargs)\n",
    "    return newfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3217,
     "status": "ok",
     "timestamp": 1605689973732,
     "user": {
      "displayName": "Alexander Dimitrienko",
      "photoUrl": "",
      "userId": "07582037467622387890"
     },
     "user_tz": -180
    },
    "id": "fuZ9bGzlkZwe"
   },
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    with tf.GradientTape() as tape:\n",
    "        return tf.math.reduce_sum(tf.multiply(y_true, tf.math.log(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1156,
     "status": "ok",
     "timestamp": 1605690176788,
     "user": {
      "displayName": "Alexander Dimitrienko",
      "photoUrl": "",
      "userId": "07582037467622387890"
     },
     "user_tz": -180
    },
    "id": "g3WLz90N4CVb"
   },
   "outputs": [],
   "source": [
    "#loss_tracker = metrics.CategoricalCrossentropy(name=\"loss\")\n",
    "acc_metric = tf.keras.metrics.Accuracy(name=\"acc\")\n",
    "\n",
    "#loss_tracker_supervised = metrics.CategoricalCrossentropy(name=\"loss_sup\")\n",
    "acc_metric_supervised = tf.keras.metrics.Accuracy(name=\"acc_sup\")\n",
    "\n",
    "#loss_tracker_unsupervised = metrics.CategoricalCrossentropy(name=\"loss_unsup\")\n",
    "acc_metric_unsupervised = tf.keras.metrics.Accuracy(name=\"acc_unsup\")\n",
    "\n",
    "\n",
    "class CustomModel(Model):\n",
    "    @is_called\n",
    "    def train_step(self, data):\n",
    "        X, Y = data\n",
    "        print(X)\n",
    "        X = tf.unstack(X)\n",
    "\n",
    "        print('Going to tape')\n",
    "\n",
    "        x_supervised = np.asarray([combined_data[i] for i in X if i in labeled])\n",
    "        x_unsupervised = np.asarray([combined_data[i] for i in X if i in unlabeled])\n",
    "        x_augmented = x_unsupervised\n",
    "        y_true_supervised = np.asarray([true_labels[i] for i in X if i in labeled])\n",
    "\n",
    "        #Supervised part\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(x_supervised)\n",
    "\n",
    "            y_pred_supervised = self(x_supervised, training=True)  \n",
    "            loss_supervised = custom_loss(y_true_supervised, y_pred_supervised)\n",
    "\n",
    "            #Unsupervised part\n",
    "            tape.watch(x_augmented)\n",
    "            y_pred = self(x_unsupervised, training=False)\n",
    "\n",
    "            #y_pred_np = tf.make_ndarray(y_pred.op.get_attr('value'))\n",
    "            y_pred_unsupervised = self(x_augmented, training=True) #if max(y_pred_np[i]) > unsupervised_threshold)\n",
    "            \n",
    "            loss_unsupervised = custom_loss(y_pred, y_pred_unsupervised)\n",
    "\n",
    "            #Loss\n",
    "            #loss, grads = custom_loss(self, y_true_supervised, y_pred, y_pred_supervised, y_pred_unsupervised)\n",
    "            loss = loss_supervised + loss_unsupervised * unsupervised_loss_coef\n",
    "            grads = tape.gradient(loss, self.trainable_variables)\n",
    "\n",
    "            #Weights\n",
    "            self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "\n",
    "        #Metrics\n",
    "        #loss_tracker_supervised.update_state(loss_supervised)\n",
    "        acc_metric_supervised.update_state(y_true_supervised, y_pred_supervised)\n",
    "\n",
    "        #loss_tracker_unsupervised.update_state(loss_unsupervised)\n",
    "        acc_metric_unsupervised.update_state(y_pred, y_pred_unsupervised)\n",
    "\n",
    "        #loss_tracker.update_state(loss)\n",
    "        #acc_metric.update_state(np.concatenate(y_pred, y_true_supervised), np.concatenate(y_pred_unsupervised, y_pred_supervised))\n",
    "\n",
    "        return {#\"loss_supervised\": loss_tracker_supervised.result(), \n",
    "                \"acc_supervised\": acc_metric_supervised.result(), \n",
    "                #\"loss_unsupervised\": loss_tracker_unsupervised.result(), \n",
    "                \"acc_unsupervised\": acc_metric_unsupervised.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [#loss_tracker, \n",
    "            acc_metric]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3695,
     "status": "ok",
     "timestamp": 1605689974228,
     "user": {
      "displayName": "Alexander Dimitrienko",
      "photoUrl": "",
      "userId": "07582037467622387890"
     },
     "user_tz": -180
    },
    "id": "MPlDyACEW6Q4"
   },
   "outputs": [],
   "source": [
    "augmentator = Augmentator(2, random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_data = np.zeros(augmented_data.shape, dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(files)):\n",
    "    data_len = files[i][b\"data\"].shape[0]\n",
    "    \n",
    "    for j in range(data_len):\n",
    "        row = files[i][b\"data\"][j]\n",
    "        true_labels[data_len * i + j][files[i][b\"labels\"][j]] = 1.\n",
    "        \n",
    "        for k in range(files[i][b\"data\"].shape[1]):\n",
    "            rotated_data[data_len * i + j][(k & 1023) >> 5][k & 31][k >> 10] = row[k]\n",
    "            \n",
    "        rotated_data[data_len * i + j] = np.rot90(rotated_data[data_len * i + j], random.choice([0, 1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(pil_data.shape[0]):\n",
    "    if i % 10000 == 0:\n",
    "        print(i)\n",
    "    pil_data[i] = np.array(augmentator(Image.fromarray(np.uint8(augmented_data[i // augment_num * augment_num]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = random.randint(0, pil_data.shape[0] // augment_num)\n",
    "for i in range(augment_num):\n",
    "    plt.imshow(augmented_data[r * augment_num + i].astype(int))\n",
    "    plt.show()\n",
    "    plt.imshow(pil_data[r * augment_num + i].astype(int))\n",
    "    plt.show()\n",
    "    print(augmented_labels[r + i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rotated_data = preprocess_input(rotated_data)\n",
    "#pil_data = preprocess_input(pil_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3226,
     "status": "ok",
     "timestamp": 1605689973730,
     "user": {
      "displayName": "Alexander Dimitrienko",
      "photoUrl": "",
      "userId": "07582037467622387890"
     },
     "user_tz": -180
    },
    "id": "WsI_XRYKb7MI"
   },
   "outputs": [],
   "source": [
    "augmentedExamplesForClass = []\n",
    "for i in range(10):\n",
    "    augmentedExamplesForClass.append([j for j in range(50000 * augment_num) if np.where(augmented_labels[j] == 1)[0][0] == i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basic_conv_model():\n",
    "    inputs = tf.keras.Input((32, 32, 3))\n",
    "    x = layers.Conv2D(32, (3, 3))(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3))(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), name = 'conv_feat')(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(256)(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dense(10, activation = 'softmax')(x)\n",
    "    \n",
    "    return CustomModel(inputs = inputs, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3680,
     "status": "ok",
     "timestamp": 1605689974229,
     "user": {
      "displayName": "Alexander Dimitrienko",
      "photoUrl": "",
      "userId": "07582037467622387890"
     },
     "user_tz": -180
    },
    "id": "lzS0LxF9biZ6"
   },
   "outputs": [],
   "source": [
    "def get_resnet_model():\n",
    "    base = tf.keras.models.load_model('emptyResNet')\n",
    "    l = base.get_layer(feature_layer).output\n",
    "    l = layers.Flatten()(l)\n",
    "    l = layers.Dropout(0.5)(l)\n",
    "    l = layers.Dense(200, kernel_regularizer=regularizers.l1_l2(l1 = 0.0001, l2 = 0.0001))(l)\n",
    "    l = layers.BatchNormalization()(l)\n",
    "    l = layers.Activation('tanh')(l)\n",
    "    l = layers.Dropout(0.5)(l)\n",
    "    l = layers.Dense(200, kernel_regularizer=regularizers.l1_l2(l1 = 0.0001, l2 = 0.0001))(l)\n",
    "    l = layers.BatchNormalization()(l)\n",
    "    l = layers.Activation('tanh')(l)\n",
    "    l = layers.Dropout(0.3)(l)\n",
    "    l = layers.Dense(10, kernel_regularizer=regularizers.l1_l2(l1 = 0.0001, l2 = 0.0001), activation = 'softmax')(l)\n",
    "\n",
    "    return tf.keras.Model(inputs = base.input, outputs = l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_labeled_unlabeled_semi(examples, percent, shuffle = True):\n",
    "    #           \n",
    "    if shuffle:\n",
    "        shuffle_examples()\n",
    "    labeled = []\n",
    "    tmp = []\n",
    "    unlabeled = []\n",
    "    \n",
    "    labeled_nums = [i for i in range(5000 - percent * 50, 5000)]\n",
    "    unlabeled_nums = [i for i in range(5000 - percent * 50)]\n",
    "\n",
    "    for i in range(len(examples)):\n",
    "        for j in labeled_nums:\n",
    "            labeled += [examples[i][j]] #50 == 5000 / 100\n",
    "        for j in unlabeled_nums:\n",
    "            unlabeled += [examples[i][j]]\n",
    "        \n",
    "    return labeled, unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vn-Pj6Zse0IK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#SEMI-SUPERVISED LEARNING\n",
    "\n",
    "val_indices = [(50000 + i) * rotations_num for i in range(10000)]\n",
    "x_val = tf.convert_to_tensor(np.take(combined_data, val_indices, axis = 0) / 256.)\n",
    "y_val = tf.convert_to_tensor(np.take(true_labels, val_indices, axis = 0))\n",
    "\n",
    "for p in labelsPercent:\n",
    "    @tf.function\n",
    "    def train_step(x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x, training=True)\n",
    "            #loss_value = custom_loss(y, logits)\n",
    "            loss_value = loss(y, logits)\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    train_acc_metric.update_state(y, logits)\n",
    "    return loss_value\n",
    "    \n",
    "    @tf.function\n",
    "    def val_step(x, y):\n",
    "        val_logits = model(x, training=False)\n",
    "        val_acc_metric.update_state(y, val_logits)\n",
    "    \n",
    "    print('%d%% of labeled data' % p)\n",
    "    model = get_cls_model(saved_name, False)\n",
    "    model.summary()\n",
    "    \n",
    "    labeled, unlabeled = generate_augmented_labeled_unlabeled(augmentedExamplesForClass, p, False)\n",
    "    \n",
    "    train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "    val_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
    "    \n",
    "    #Custom training loop\n",
    "    for epoch in range(semisupervised_epochs):\n",
    "        above_threshold_num = 0\n",
    "        start_time = time.time()\n",
    "        random.shuffle(labeled)\n",
    "        random.shuffle(unlabeled)\n",
    "        print(\"\\nEpoch \" + str(epoch) + \"/\" + str(semisupervised_epochs))\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for step_num in range(augmented_data.shape[0] // semisupervised_batch_size):\n",
    "            print('Processing step %d/%d, train_acc = %.4f\\r' % (step_num, augmented_data.shape[0] // semisupervised_batch_size, float(train_acc_metric.result())), end=\"\")\n",
    "            labeled_batch_indices = labeled[step_num * semisupervised_batch_size * p // 100 : (step_num + 1) * semisupervised_batch_size * p // 100 ]\n",
    "            unlabeled_batch_indices = unlabeled[step_num * semisupervised_batch_size * (100 - p) // 100 : (step_num + 1) * semisupervised_batch_size * (100 - p) // 100 ]\n",
    "            loss_value_labeled = train_step(tf.convert_to_tensor(np.take(augmented_data, labeled_batch_indices, axis = 0) / 256.), \n",
    "                                            tf.convert_to_tensor(np.take(augmented_labels, labeled_batch_indices, axis = 0)))\n",
    "         \n",
    "            if epoch >= unlabeled_epoch_start:\n",
    "                x_batch_unlabeled = tf.convert_to_tensor(np.take(augmented_data, unlabeled_batch_indices, axis = 0) / 256.)\n",
    "                y_true_unlabeled = model(x_batch_unlabeled, training=False)\n",
    "                \n",
    "                #check threshold\n",
    "                indices_above_threshold = np.take(unlabeled_batch_indices, tf.where(tf.reduce_max(y_true_unlabeled, axis = 1) > unsupervised_threshold)).flatten()\n",
    "                loss_value_unlabeled = 0.0\n",
    "                if indices_above_threshold.shape[0] > 0:\n",
    "                    above_threshold_num += indices_above_threshold.shape[0]\n",
    "                    loss_value_unlabeled = train_step(tf.convert_to_tensor(np.take(pil_data, indices_above_threshold, axis = 0) / 256.), \n",
    "                                                      tf.cast(tf.convert_to_tensor(np.take(y_true_unlabeled.numpy(), tf.where(tf.reduce_max(y_true_unlabeled, axis = 1) > unsupervised_threshold).numpy().flatten(), axis = 0)) + 0.5, tf.int32))\n",
    "\n",
    "            \n",
    "            #print('Step ' + str(step) + ' Loss: ' + str(loss_value_labeled) + ' | ' + str(loss_value_unlabeled))\n",
    "            \n",
    "            #optimizer.lr.assign(lr_schedule_conv(optimizer.lr, epoch))\n",
    "              \n",
    "        print(\"\\nTraining acc over epoch: %.4f\" % (float(train_acc_metric.result()),))\n",
    "        \n",
    "        val_step(x_val, y_val)\n",
    "        print(\"Val acc over epoch: %.4f\" % (float(val_acc_metric.result()),))\n",
    "\n",
    "        train_acc_metric.reset_states()\n",
    "        val_acc_metric.reset_states()\n",
    "        \n",
    "        print(\"%d/%d unlabeled samples are used\" % (above_threshold_num, len(unlabeled)))\n",
    "        print(\"%s seconds for epoch\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#FINE-TUNING AFTER SELF-SUPERVISED\n",
    "\n",
    "val_indices = [(50000 + i) * rotations_num for i in range(10000)]\n",
    "x_val = tf.convert_to_tensor(np.take(combined_data, val_indices, axis = 0) / 256.)\n",
    "y_val = tf.convert_to_tensor(np.take(true_labels, val_indices, axis = 0))\n",
    "\n",
    "for p in [3, 25, 50]:\n",
    "    @tf.function\n",
    "    def train_step(x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x, training=True)\n",
    "            #loss_value = custom_loss(y, logits)\n",
    "            loss_value = loss(y, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        train_acc_metric.update_state(y, logits)\n",
    "        return loss_value\n",
    "    \n",
    "    @tf.function\n",
    "    def val_step(x, y):\n",
    "        val_logits = model(x, training=False)\n",
    "        val_acc_metric.update_state(y, val_logits)\n",
    "\n",
    "    print('%d%% of labeled data' % p)\n",
    "    model = get_cls_model(saved_name, True)\n",
    "    model.summary()\n",
    "    \n",
    "    labeled, unlabeled = generate_augmented_labeled_unlabeled(augmentedExamplesForClass, p, False)\n",
    "    \n",
    "    train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "    val_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    \n",
    "    #Custom training loop\n",
    "    for epoch in range(semisupervised_epochs):\n",
    "        above_threshold_num = 0\n",
    "        start_time = time.time()\n",
    "        random.shuffle(labeled)\n",
    "        print(\"\\nEpoch \" + str(epoch) + \"/\" + str(semisupervised_epochs))\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for step_num in range(len(labeled) // semisupervised_batch_size):\n",
    "            print('Processing step %d/%d, train_acc = %.4f\\r' % (step_num, augmented_data.shape[0] // semisupervised_batch_size, float(train_acc_metric.result())), end=\"\")\n",
    "            labeled_batch_indices = labeled[step_num * semisupervised_batch_size: (step_num + 1) * semisupervised_batch_size]\n",
    "            loss_value_labeled = train_step(tf.convert_to_tensor(np.take(augmented_data, labeled_batch_indices, axis = 0) / 256.), \n",
    "                                            tf.convert_to_tensor(np.take(augmented_labels, labeled_batch_indices, axis = 0)))\n",
    "         \n",
    "           \n",
    "            #print('Step ' + str(step) + ' Loss: ' + str(loss_value_labeled) + ' | ' + str(loss_value_unlabeled))\n",
    "            \n",
    "        #optimizer.lr.assign(lr_schedule_cls(optimizer.lr, epoch))\n",
    "              \n",
    "        print(\"\\nTraining acc over epoch: %.4f\" % (float(train_acc_metric.result()),))\n",
    "        \n",
    "        val_step(x_val, y_val)\n",
    "        print(\"Val acc over epoch: %.4f\" % (float(val_acc_metric.result()),))\n",
    "\n",
    "        train_acc_metric.reset_states()\n",
    "        val_acc_metric.reset_states()\n",
    "        \n",
    "        print(\"%d/%d unlabeled samples are used\" % (above_threshold_num, len(unlabeled)))\n",
    "        print(\"%s seconds for epoch\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SelfSupervision.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
